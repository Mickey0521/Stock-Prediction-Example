{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector,Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Open    High     Low   Close      Volume\n",
       "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = pd.read_csv('../data/stock50.csv')\n",
    "# train = pd.read_csv('stock50.csv')\n",
    "train = pd.read_csv('Google_Stock_Price_v2.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>790.90</td>\n",
       "      <td>792.74</td>\n",
       "      <td>789.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>790.68</td>\n",
       "      <td>797.86</td>\n",
       "      <td>791.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>793.70</td>\n",
       "      <td>794.23</td>\n",
       "      <td>785.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>783.33</td>\n",
       "      <td>785.93</td>\n",
       "      <td>782.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>782.75</td>\n",
       "      <td>782.78</td>\n",
       "      <td>771.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open    High   Close\n",
       "1144  790.90  792.74  789.91\n",
       "1145  790.68  797.86  791.55\n",
       "1146  793.70  794.23  785.05\n",
       "1147  783.33  785.93  782.79\n",
       "1148  782.75  782.78  771.82"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train\n",
    "\n",
    "df.drop(df.columns[[0,3,5]], axis=1, inplace=True) \n",
    "\n",
    "df['High'] = df['High'] \n",
    "df['Open'] = df['Open'] \n",
    "df['Close'] =df['Close'] \n",
    "\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>0.79090</td>\n",
       "      <td>0.79274</td>\n",
       "      <td>0.78991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>0.79068</td>\n",
       "      <td>0.79786</td>\n",
       "      <td>0.79155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>0.79370</td>\n",
       "      <td>0.79423</td>\n",
       "      <td>0.78505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>0.78333</td>\n",
       "      <td>0.78593</td>\n",
       "      <td>0.78279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>0.78275</td>\n",
       "      <td>0.78278</td>\n",
       "      <td>0.77182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open     High    Close\n",
       "1144  0.79090  0.79274  0.78991\n",
       "1145  0.79068  0.79786  0.79155\n",
       "1146  0.79370  0.79423  0.78505\n",
       "1147  0.78333  0.78593  0.78279\n",
       "1148  0.78275  0.78278  0.77182"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['High'] = df['High'] / 1000\n",
    "df['Open'] = df['Open'] / 1000\n",
    "df['Close'] = df['Close'].astype(float) / 1000\n",
    "\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "stock_name = 'Google'\n",
    "\n",
    "today = datetime.date.today()\n",
    "file_name = stock_name+'_stock_%s.csv' % today\n",
    "df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    data = stock.as_matrix() #pd.DataFrame(stock)\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "\n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1][:,-1]\n",
    "    x_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1][:,-1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[2]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\",metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "def build_model2(layers):\n",
    "        d = 0.2\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(128, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "        model.add(Dropout(d))\n",
    "        model.add(LSTM(64, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "        model.add(Dropout(d))\n",
    "        model.add(Dense(16,init='uniform',activation='relu'))        \n",
    "        model.add(Dense(1,init='uniform',activation='relu'))\n",
    "        model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (1029, 5, 3)\n",
      "y_train (1029,)\n",
      "X_test (114, 5, 3)\n",
      "y_test (114,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\myTensorFlow-Gpu-V2\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "window = 5\n",
    "X_train, y_train, X_test, y_test = load_data(df[::-1], window)\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train [[0.78275 0.78278 0.77182]\n",
      " [0.78333 0.78593 0.78279]\n",
      " [0.7937  0.79423 0.78505]\n",
      " [0.79068 0.79786 0.79155]\n",
      " [0.7909  0.79274 0.78991]]\n",
      "y_train 0.79126\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\", X_train[0])\n",
    "print(\"y_train\", y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\myTensorFlow-Gpu-V2\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "C:\\Users\\user\\Anaconda3\\envs\\myTensorFlow-Gpu-V2\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"relu\", kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "model = build_model2([3,window,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\myTensorFlow-Gpu-V2\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 823 samples, validate on 206 samples\n",
      "Epoch 1/500\n",
      "823/823 [==============================] - 2s 3ms/step - loss: 0.4712 - acc: 0.0000e+00 - val_loss: 0.5010 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "823/823 [==============================] - 0s 106us/step - loss: 0.4680 - acc: 0.0000e+00 - val_loss: 0.4972 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.4638 - acc: 0.0000e+00 - val_loss: 0.4927 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "823/823 [==============================] - 0s 114us/step - loss: 0.4588 - acc: 0.0000e+00 - val_loss: 0.4870 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.4526 - acc: 0.0000e+00 - val_loss: 0.4797 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.4442 - acc: 0.0000e+00 - val_loss: 0.4700 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.4329 - acc: 0.0000e+00 - val_loss: 0.4566 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "823/823 [==============================] - 0s 105us/step - loss: 0.4170 - acc: 0.0000e+00 - val_loss: 0.4376 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.3940 - acc: 0.0000e+00 - val_loss: 0.4097 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.3604 - acc: 0.0000e+00 - val_loss: 0.3687 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.3129 - acc: 0.0000e+00 - val_loss: 0.3109 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.2492 - acc: 0.0000e+00 - val_loss: 0.2350 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.1746 - acc: 0.0000e+00 - val_loss: 0.1475 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0958 - acc: 0.0000e+00 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0078 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "823/823 [==============================] - 0s 133us/step - loss: 0.0436 - acc: 0.0000e+00 - val_loss: 0.0223 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "823/823 [==============================] - 0s 110us/step - loss: 0.0599 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0485 - acc: 0.0000e+00 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "823/823 [==============================] - 0s 102us/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0163 - acc: 0.0000e+00 - val_loss: 0.0173 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0207 - acc: 0.0000e+00 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0243 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0209 - acc: 0.0000e+00 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0163 - acc: 0.0000e+00 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0076 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0162 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "823/823 [==============================] - 0s 115us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0145 - acc: 0.0000e+00 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "823/823 [==============================] - 0s 102us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0066 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "823/823 [==============================] - 0s 118us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "823/823 [==============================] - 0s 115us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0140 - acc: 0.0000e+00 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "823/823 [==============================] - 0s 82us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0145 - acc: 0.0000e+00 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0143 - acc: 0.0000e+00 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0145 - acc: 0.0000e+00 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "823/823 [==============================] - 0s 80us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "823/823 [==============================] - 0s 82us/step - loss: 0.0141 - acc: 0.0000e+00 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "823/823 [==============================] - 0s 80us/step - loss: 0.0141 - acc: 0.0000e+00 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0139 - acc: 0.0000e+00 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0140 - acc: 0.0000e+00 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0142 - acc: 0.0000e+00 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0137 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 82/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 83/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 84/500\n",
      "823/823 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 85/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 86/500\n",
      "823/823 [==============================] - 0s 120us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 87/500\n",
      "823/823 [==============================] - 0s 102us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 88/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.0104 - acc: 0.0000e+00 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 89/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0100 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 90/500\n",
      "823/823 [==============================] - 0s 109us/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 91/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 92/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 93/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 94/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0070 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 95/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0064 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 96/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0060 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 97/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 98/500\n",
      "823/823 [==============================] - 0s 102us/step - loss: 0.0050 - acc: 0.0000e+00 - val_loss: 9.3317e-04 - val_acc: 0.0000e+00\n",
      "Epoch 99/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 100/500\n",
      "823/823 [==============================] - 0s 105us/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 101/500\n",
      "823/823 [==============================] - 0s 111us/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 102/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 103/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 104/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 105/500\n",
      "823/823 [==============================] - 0s 102us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 106/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 107/500\n",
      "823/823 [==============================] - 0s 102us/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 108/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 109/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
      "Epoch 110/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 111/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 112/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 113/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 114/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823/823 [==============================] - 0s 102us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 116/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 117/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 118/500\n",
      "823/823 [==============================] - 0s 109us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 119/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 120/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 121/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 122/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 123/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 124/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 125/500\n",
      "823/823 [==============================] - 0s 107us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 126/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 127/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 128/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 129/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 130/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 131/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 132/500\n",
      "823/823 [==============================] - 0s 110us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 133/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 134/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 135/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 136/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 137/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 138/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 139/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 140/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 141/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 142/500\n",
      "823/823 [==============================] - 0s 109us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 143/500\n",
      "823/823 [==============================] - 0s 122us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 144/500\n",
      "823/823 [==============================] - 0s 118us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 145/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 146/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 147/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 148/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 149/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 150/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 151/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "823/823 [==============================] - 0s 108us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 153/500\n",
      "823/823 [==============================] - 0s 102us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 154/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 155/500\n",
      "823/823 [==============================] - 0s 107us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 156/500\n",
      "823/823 [==============================] - 0s 108us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 157/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 158/500\n",
      "823/823 [==============================] - 0s 109us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 159/500\n",
      "823/823 [==============================] - 0s 102us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 160/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 161/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 162/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 163/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 164/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 165/500\n",
      "823/823 [==============================] - 0s 102us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 166/500\n",
      "823/823 [==============================] - 0s 110us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 167/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 168/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 169/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 170/500\n",
      "823/823 [==============================] - 0s 105us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 171/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 173/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 174/500\n",
      "823/823 [==============================] - 0s 80us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 175/500\n",
      "823/823 [==============================] - 0s 80us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 176/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 177/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 178/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 179/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 180/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 181/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 182/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 183/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 184/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 185/500\n",
      "823/823 [==============================] - 0s 82us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 186/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 187/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 188/500\n",
      "823/823 [==============================] - 0s 118us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 189/500\n",
      "823/823 [==============================] - 0s 105us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 190/500\n",
      "823/823 [==============================] - 0s 107us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 191/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 192/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 193/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 194/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 195/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 196/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 197/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 198/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 199/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 200/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 201/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 202/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 203/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 204/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 205/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 206/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 207/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 208/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 209/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 210/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 211/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 212/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 213/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 214/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 215/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 216/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 217/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 218/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 219/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 220/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 221/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 222/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 223/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 224/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 225/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 226/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 227/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 228/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 230/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 231/500\n",
      "823/823 [==============================] - 0s 81us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 232/500\n",
      "823/823 [==============================] - 0s 82us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 233/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 234/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 235/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 236/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 237/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 238/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 239/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 240/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 241/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 242/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 243/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 244/500\n",
      "823/823 [==============================] - 0s 82us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 245/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 246/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 247/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 248/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 249/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 250/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 251/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 252/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 253/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 254/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 255/500\n",
      "823/823 [==============================] - 0s 102us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 256/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 257/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 258/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 259/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 260/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 261/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 262/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 263/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 264/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 265/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 266/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 267/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 268/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 269/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 270/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 271/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 272/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 273/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 274/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 275/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 9.5792e-04 - val_acc: 0.0000e+00\n",
      "Epoch 276/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 277/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 278/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 279/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 280/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 281/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 282/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 9.8143e-04 - val_acc: 0.0000e+00\n",
      "Epoch 283/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 284/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 285/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 287/500\n",
      "823/823 [==============================] - 0s 81us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 288/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 289/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 290/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 9.3387e-04 - val_acc: 0.0000e+00\n",
      "Epoch 291/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 292/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 293/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 294/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 295/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 296/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 297/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 298/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 299/500\n",
      "823/823 [==============================] - 0s 82us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 300/500\n",
      "823/823 [==============================] - 0s 81us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 9.5559e-04 - val_acc: 0.0000e+00\n",
      "Epoch 301/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 9.5288e-04 - val_acc: 0.0000e+00\n",
      "Epoch 302/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 303/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 304/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 9.5010e-04 - val_acc: 0.0000e+00\n",
      "Epoch 305/500\n",
      "823/823 [==============================] - 0s 81us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 9.8598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 306/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 307/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 6.9624e-04 - val_acc: 0.0000e+00\n",
      "Epoch 308/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 9.6248e-04 - val_acc: 0.0000e+00\n",
      "Epoch 309/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 310/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 7.7753e-04 - val_acc: 0.0000e+00\n",
      "Epoch 311/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 9.3598e-04 - val_acc: 0.0000e+00\n",
      "Epoch 312/500\n",
      "823/823 [==============================] - 0s 82us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 313/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 9.9108e-04 - val_acc: 0.0000e+00\n",
      "Epoch 314/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 315/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 316/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 8.2533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 317/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 9.3908e-04 - val_acc: 0.0000e+00\n",
      "Epoch 318/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 319/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 320/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 8.6175e-04 - val_acc: 0.0000e+00\n",
      "Epoch 321/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 322/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 9.8446e-04 - val_acc: 0.0000e+00\n",
      "Epoch 323/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 8.4516e-04 - val_acc: 0.0000e+00\n",
      "Epoch 324/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 325/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 9.0470e-04 - val_acc: 0.0000e+00\n",
      "Epoch 326/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 7.4655e-04 - val_acc: 0.0000e+00\n",
      "Epoch 327/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 328/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 329/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 6.9703e-04 - val_acc: 0.0000e+00\n",
      "Epoch 330/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 331/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 332/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 7.5190e-04 - val_acc: 0.0000e+00\n",
      "Epoch 333/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 334/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 335/500\n",
      "823/823 [==============================] - 0s 82us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 7.7731e-04 - val_acc: 0.0000e+00\n",
      "Epoch 336/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 337/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 7.4950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 338/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.3459e-04 - val_acc: 0.0000e+00\n",
      "Epoch 339/500\n",
      "823/823 [==============================] - 0s 103us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 340/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 8.0209e-04 - val_acc: 0.0000e+00\n",
      "Epoch 341/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.7280e-04 - val_acc: 0.0000e+00\n",
      "Epoch 342/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823/823 [==============================] - 0s 91us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 343/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 344/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 7.3749e-04 - val_acc: 0.0000e+00\n",
      "Epoch 345/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 346/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 347/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 6.6607e-04 - val_acc: 0.0000e+00\n",
      "Epoch 348/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 349/500\n",
      "823/823 [==============================] - 0s 81us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 350/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 6.3677e-04 - val_acc: 0.0000e+00\n",
      "Epoch 351/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 352/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 353/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 5.5358e-04 - val_acc: 0.0000e+00\n",
      "Epoch 354/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 8.5836e-04 - val_acc: 0.0000e+00\n",
      "Epoch 355/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 356/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 5.9760e-04 - val_acc: 0.0000e+00\n",
      "Epoch 357/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 7.6583e-04 - val_acc: 0.0000e+00\n",
      "Epoch 358/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 359/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 8.0279e-04 - val_acc: 0.0000e+00\n",
      "Epoch 360/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 8.9024e-04 - val_acc: 0.0000e+00\n",
      "Epoch 361/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 8.5014e-04 - val_acc: 0.0000e+00\n",
      "Epoch 362/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 8.4972e-04 - val_acc: 0.0000e+00\n",
      "Epoch 363/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 364/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 8.0734e-04 - val_acc: 0.0000e+00\n",
      "Epoch 365/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 7.7208e-04 - val_acc: 0.0000e+00\n",
      "Epoch 366/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 367/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 6.5513e-04 - val_acc: 0.0000e+00\n",
      "Epoch 368/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 8.0086e-04 - val_acc: 0.0000e+00\n",
      "Epoch 369/500\n",
      "823/823 [==============================] - 0s 107us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 370/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 8.8140e-04 - val_acc: 0.0000e+00\n",
      "Epoch 371/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 8.7327e-04 - val_acc: 0.0000e+00\n",
      "Epoch 372/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 373/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 7.1328e-04 - val_acc: 0.0000e+00\n",
      "Epoch 374/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 9.3344e-04 - val_acc: 0.0000e+00\n",
      "Epoch 375/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 376/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 8.8991e-04 - val_acc: 0.0000e+00\n",
      "Epoch 377/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 5.8780e-04 - val_acc: 0.0000e+00\n",
      "Epoch 378/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 379/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 380/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 6.9875e-04 - val_acc: 0.0000e+00\n",
      "Epoch 381/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 8.9705e-04 - val_acc: 0.0000e+00\n",
      "Epoch 382/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 383/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 6.5840e-04 - val_acc: 0.0000e+00\n",
      "Epoch 384/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 6.6486e-04 - val_acc: 0.0000e+00\n",
      "Epoch 385/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 386/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 9.2920e-04 - val_acc: 0.0000e+00\n",
      "Epoch 387/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 5.4228e-04 - val_acc: 0.0000e+00\n",
      "Epoch 388/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 9.0771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 389/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 390/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 5.3950e-04 - val_acc: 0.0000e+00\n",
      "Epoch 391/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 9.8171e-04 - val_acc: 0.0000e+00\n",
      "Epoch 392/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 393/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 5.3152e-04 - val_acc: 0.0000e+00\n",
      "Epoch 394/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 8.8737e-04 - val_acc: 0.0000e+00\n",
      "Epoch 395/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 396/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 8.3255e-04 - val_acc: 0.0000e+00\n",
      "Epoch 397/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823/823 [==============================] - 0s 107us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.3976e-04 - val_acc: 0.0000e+00\n",
      "Epoch 399/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 7.7769e-04 - val_acc: 0.0000e+00\n",
      "Epoch 400/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 401/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.1831e-04 - val_acc: 0.0000e+00\n",
      "Epoch 402/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 7.6791e-04 - val_acc: 0.0000e+00\n",
      "Epoch 403/500\n",
      "823/823 [==============================] - 0s 108us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 404/500\n",
      "823/823 [==============================] - 0s 108us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 4.9181e-04 - val_acc: 0.0000e+00\n",
      "Epoch 405/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 8.1080e-04 - val_acc: 0.0000e+00\n",
      "Epoch 406/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 9.5501e-04 - val_acc: 0.0000e+00\n",
      "Epoch 407/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 6.2488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 408/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 7.8065e-04 - val_acc: 0.0000e+00\n",
      "Epoch 409/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 410/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.0408e-04 - val_acc: 0.0000e+00\n",
      "Epoch 411/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 7.6350e-04 - val_acc: 0.0000e+00\n",
      "Epoch 412/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 9.2123e-04 - val_acc: 0.0000e+00\n",
      "Epoch 413/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 7.6964e-04 - val_acc: 0.0000e+00\n",
      "Epoch 414/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 9.5113e-04 - val_acc: 0.0000e+00\n",
      "Epoch 415/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 9.0629e-04 - val_acc: 0.0000e+00\n",
      "Epoch 416/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 8.2702e-04 - val_acc: 0.0000e+00\n",
      "Epoch 417/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 8.1778e-04 - val_acc: 0.0000e+00\n",
      "Epoch 418/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 7.5425e-04 - val_acc: 0.0000e+00\n",
      "Epoch 419/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 6.9686e-04 - val_acc: 0.0000e+00\n",
      "Epoch 420/500\n",
      "823/823 [==============================] - 0s 81us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 6.5072e-04 - val_acc: 0.0000e+00\n",
      "Epoch 421/500\n",
      "823/823 [==============================] - 0s 82us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.0480e-04 - val_acc: 0.0000e+00\n",
      "Epoch 422/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 6.2560e-04 - val_acc: 0.0000e+00\n",
      "Epoch 423/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 7.4121e-04 - val_acc: 0.0000e+00\n",
      "Epoch 424/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 8.7713e-04 - val_acc: 0.0000e+00\n",
      "Epoch 425/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 5.9961e-04 - val_acc: 0.0000e+00\n",
      "Epoch 426/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 6.1884e-04 - val_acc: 0.0000e+00\n",
      "Epoch 427/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 9.8019e-04 - val_acc: 0.0000e+00\n",
      "Epoch 428/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 5.1057e-04 - val_acc: 0.0000e+00\n",
      "Epoch 429/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 7.4439e-04 - val_acc: 0.0000e+00\n",
      "Epoch 430/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 7.7812e-04 - val_acc: 0.0000e+00\n",
      "Epoch 431/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 5.0291e-04 - val_acc: 0.0000e+00\n",
      "Epoch 432/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 8.1022e-04 - val_acc: 0.0000e+00\n",
      "Epoch 433/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 8.5449e-04 - val_acc: 0.0000e+00\n",
      "Epoch 434/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 6.2779e-04 - val_acc: 0.0000e+00\n",
      "Epoch 435/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 8.2912e-04 - val_acc: 0.0000e+00\n",
      "Epoch 436/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 7.1748e-04 - val_acc: 0.0000e+00\n",
      "Epoch 437/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 3.7464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 438/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 9.8140e-04 - val_acc: 0.0000e+00\n",
      "Epoch 439/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 8.8053e-04 - val_acc: 0.0000e+00\n",
      "Epoch 440/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 4.6740e-04 - val_acc: 0.0000e+00\n",
      "Epoch 441/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 9.1555e-04 - val_acc: 0.0000e+00\n",
      "Epoch 442/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 7.9096e-04 - val_acc: 0.0000e+00\n",
      "Epoch 443/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 5.1615e-04 - val_acc: 0.0000e+00\n",
      "Epoch 444/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 8.0116e-04 - val_acc: 0.0000e+00\n",
      "Epoch 445/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 7.9747e-04 - val_acc: 0.0000e+00\n",
      "Epoch 446/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 5.8260e-04 - val_acc: 0.0000e+00\n",
      "Epoch 447/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.6171e-04 - val_acc: 0.0000e+00\n",
      "Epoch 448/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.6267e-04 - val_acc: 0.0000e+00\n",
      "Epoch 449/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 7.5488e-04 - val_acc: 0.0000e+00\n",
      "Epoch 450/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 7.6858e-04 - val_acc: 0.0000e+00\n",
      "Epoch 451/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 5.8502e-04 - val_acc: 0.0000e+00\n",
      "Epoch 452/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 9.0344e-04 - val_acc: 0.0000e+00\n",
      "Epoch 453/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823/823 [==============================] - 0s 96us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 9.4185e-04 - val_acc: 0.0000e+00\n",
      "Epoch 454/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.0058e-04 - val_acc: 0.0000e+00\n",
      "Epoch 455/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 7.6415e-04 - val_acc: 0.0000e+00\n",
      "Epoch 456/500\n",
      "823/823 [==============================] - 0s 84us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 8.5254e-04 - val_acc: 0.0000e+00\n",
      "Epoch 457/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 4.9568e-04 - val_acc: 0.0000e+00\n",
      "Epoch 458/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 9.7714e-04 - val_acc: 0.0000e+00\n",
      "Epoch 459/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.0980e-04 - val_acc: 0.0000e+00\n",
      "Epoch 460/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 4.5688e-04 - val_acc: 0.0000e+00\n",
      "Epoch 461/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 7.8601e-04 - val_acc: 0.0000e+00\n",
      "Epoch 462/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 4.3822e-04 - val_acc: 0.0000e+00\n",
      "Epoch 463/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 6.0748e-04 - val_acc: 0.0000e+00\n",
      "Epoch 464/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.6270e-04 - val_acc: 0.0000e+00\n",
      "Epoch 465/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 4.9012e-04 - val_acc: 0.0000e+00\n",
      "Epoch 466/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 4.5247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 467/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 6.9533e-04 - val_acc: 0.0000e+00\n",
      "Epoch 468/500\n",
      "823/823 [==============================] - 0s 86us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 5.3371e-04 - val_acc: 0.0000e+00\n",
      "Epoch 469/500\n",
      "823/823 [==============================] - 0s 99us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 4.5583e-04 - val_acc: 0.0000e+00\n",
      "Epoch 470/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 9.0785e-04 - val_acc: 0.0000e+00\n",
      "Epoch 471/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 5.9625e-04 - val_acc: 0.0000e+00\n",
      "Epoch 472/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 5.3771e-04 - val_acc: 0.0000e+00\n",
      "Epoch 473/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 9.7765e-04 - val_acc: 0.0000e+00\n",
      "Epoch 474/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 4.5114e-04 - val_acc: 0.0000e+00\n",
      "Epoch 475/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 6.1775e-04 - val_acc: 0.0000e+00\n",
      "Epoch 476/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 8.1512e-04 - val_acc: 0.0000e+00\n",
      "Epoch 477/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 3.9590e-04 - val_acc: 0.0000e+00\n",
      "Epoch 478/500\n",
      "823/823 [==============================] - 0s 92us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 7.9459e-04 - val_acc: 0.0000e+00\n",
      "Epoch 479/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 6.3094e-04 - val_acc: 0.0000e+00\n",
      "Epoch 480/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 4.1940e-04 - val_acc: 0.0000e+00\n",
      "Epoch 481/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 5.7056e-04 - val_acc: 0.0000e+00\n",
      "Epoch 482/500\n",
      "823/823 [==============================] - 0s 93us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 7.9399e-04 - val_acc: 0.0000e+00\n",
      "Epoch 483/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 5.5001e-04 - val_acc: 0.0000e+00\n",
      "Epoch 484/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 5.4707e-04 - val_acc: 0.0000e+00\n",
      "Epoch 485/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 9.0120e-04 - val_acc: 0.0000e+00\n",
      "Epoch 486/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 4.9464e-04 - val_acc: 0.0000e+00\n",
      "Epoch 487/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.4664e-04 - val_acc: 0.0000e+00\n",
      "Epoch 488/500\n",
      "823/823 [==============================] - 0s 91us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 8.6873e-04 - val_acc: 0.0000e+00\n",
      "Epoch 489/500\n",
      "823/823 [==============================] - 0s 95us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.5220e-04 - val_acc: 0.0000e+00\n",
      "Epoch 490/500\n",
      "823/823 [==============================] - 0s 90us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 3.8243e-04 - val_acc: 0.0000e+00\n",
      "Epoch 491/500\n",
      "823/823 [==============================] - 0s 88us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 8.4465e-04 - val_acc: 0.0000e+00\n",
      "Epoch 492/500\n",
      "823/823 [==============================] - 0s 85us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 6.6330e-04 - val_acc: 0.0000e+00\n",
      "Epoch 493/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 3.6776e-04 - val_acc: 0.0000e+00\n",
      "Epoch 494/500\n",
      "823/823 [==============================] - 0s 104us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 9.7605e-04 - val_acc: 0.0000e+00\n",
      "Epoch 495/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 3.8843e-04 - val_acc: 0.0000e+00\n",
      "Epoch 496/500\n",
      "823/823 [==============================] - 0s 97us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 4.8916e-04 - val_acc: 0.0000e+00\n",
      "Epoch 497/500\n",
      "823/823 [==============================] - 0s 87us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 7.2042e-04 - val_acc: 0.0000e+00\n",
      "Epoch 498/500\n",
      "823/823 [==============================] - 0s 101us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 3.4306e-04 - val_acc: 0.0000e+00\n",
      "Epoch 499/500\n",
      "823/823 [==============================] - 0s 98us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 6.1657e-04 - val_acc: 0.0000e+00\n",
      "Epoch 500/500\n",
      "823/823 [==============================] - 0s 96us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 6.7676e-04 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2595bb8df28>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    nb_epoch=500,\n",
    "    validation_split=0.2,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00 MSE (0.03 RMSE)\n",
      "Test Score: 0.00 MSE (0.02 RMSE)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_test[-1])\n",
    "diff=[]\n",
    "ratio=[]\n",
    "p = model.predict(X_test)\n",
    "for u in range(len(y_test)):\n",
    "    pr = p[u][0]\n",
    "    ratio.append((y_test[u]/pr)-1)\n",
    "    diff.append(abs(y_test[u]- pr))\n",
    "    #print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56296 0.55752 0.55955 0.56355 0.56694 0.57886 0.57665 0.57898 0.56885\n",
      " 0.57701 0.56942 0.57927 0.58662 0.59271 0.58991 0.60201 0.60779 0.59916\n",
      " 0.61243 0.59876 0.62134 0.62721 0.60944 0.60235 0.60357 0.61198 0.60748\n",
      " 0.61111 0.60589 0.59534 0.60935 0.6056  0.60278 0.60319 0.6133  0.61378\n",
      " 0.60805 0.59962 0.59596 0.59443 0.59766 0.60579 0.6079  0.60441 0.62289\n",
      " 0.64923 0.63422 0.62514 0.62911 0.63059 0.63341 0.64086 0.64515 0.63948\n",
      " 0.64663 0.65396 0.64525 0.64755 0.64083 0.64428 0.63823 0.63176 0.63224\n",
      " 0.62333 0.61943 0.6143  0.61609 0.60349 0.59861 0.60548 0.60514 0.6033\n",
      " 0.61257 0.61955 0.6207  0.61656 0.6167  0.60764 0.60823 0.60445 0.60628\n",
      " 0.61232 0.60298 0.60486 0.6039  0.60809 0.61052 0.60425 0.60979 0.60818\n",
      " 0.60511 0.60742 0.5947  0.58351 0.57924 0.57852 0.57611 0.57839 0.56654\n",
      " 0.56793 0.57934 0.58392 0.58439 0.63782 0.63118 0.62686 0.62328 0.62792\n",
      " 0.62425 0.62143 0.62076 0.64824 0.65721 0.66645]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57815945]\n",
      " [0.5782491 ]\n",
      " [0.5822447 ]\n",
      " [0.57907355]\n",
      " [0.5717373 ]\n",
      " [0.56834364]\n",
      " [0.56808686]\n",
      " [0.57208115]\n",
      " [0.577003  ]\n",
      " [0.58146524]\n",
      " [0.5860475 ]\n",
      " [0.5841542 ]\n",
      " [0.5834018 ]\n",
      " [0.5812305 ]\n",
      " [0.5856087 ]\n",
      " [0.5872552 ]\n",
      " [0.59530723]\n",
      " [0.6014879 ]\n",
      " [0.60588026]\n",
      " [0.60899556]\n",
      " [0.6155485 ]\n",
      " [0.6177875 ]\n",
      " [0.6177093 ]\n",
      " [0.62344205]\n",
      " [0.62272155]\n",
      " [0.6308792 ]\n",
      " [0.6274133 ]\n",
      " [0.61820996]\n",
      " [0.616671  ]\n",
      " [0.61893976]\n",
      " [0.6211159 ]\n",
      " [0.6187057 ]\n",
      " [0.6180365 ]\n",
      " [0.6146414 ]\n",
      " [0.61325204]\n",
      " [0.61843175]\n",
      " [0.6170249 ]\n",
      " [0.6174468 ]\n",
      " [0.6198399 ]\n",
      " [0.6224947 ]\n",
      " [0.61893713]\n",
      " [0.6131917 ]\n",
      " [0.60868615]\n",
      " [0.6081042 ]\n",
      " [0.6098728 ]\n",
      " [0.61486506]\n",
      " [0.6216797 ]\n",
      " [0.6268959 ]\n",
      " [0.6338371 ]\n",
      " [0.64640325]\n",
      " [0.6526048 ]\n",
      " [0.6442244 ]\n",
      " [0.6421914 ]\n",
      " [0.6459169 ]\n",
      " [0.6491292 ]\n",
      " [0.65325093]\n",
      " [0.6577652 ]\n",
      " [0.65963936]\n",
      " [0.6596411 ]\n",
      " [0.6634172 ]\n",
      " [0.6639408 ]\n",
      " [0.6595986 ]\n",
      " [0.65838015]\n",
      " [0.6545158 ]\n",
      " [0.65262437]\n",
      " [0.64693797]\n",
      " [0.64206237]\n",
      " [0.6383515 ]\n",
      " [0.6318949 ]\n",
      " [0.62744164]\n",
      " [0.6231267 ]\n",
      " [0.61995816]\n",
      " [0.6139816 ]\n",
      " [0.61395967]\n",
      " [0.617947  ]\n",
      " [0.6197519 ]\n",
      " [0.62305886]\n",
      " [0.629003  ]\n",
      " [0.63132244]\n",
      " [0.6295897 ]\n",
      " [0.62592506]\n",
      " [0.6231898 ]\n",
      " [0.6190461 ]\n",
      " [0.61871135]\n",
      " [0.6177692 ]\n",
      " [0.61874384]\n",
      " [0.61916405]\n",
      " [0.6159793 ]\n",
      " [0.6172959 ]\n",
      " [0.6181413 ]\n",
      " [0.62013745]\n",
      " [0.6200526 ]\n",
      " [0.61835194]\n",
      " [0.6193323 ]\n",
      " [0.61631083]\n",
      " [0.61191   ]\n",
      " [0.6065009 ]\n",
      " [0.5964034 ]\n",
      " [0.5896618 ]\n",
      " [0.5866987 ]\n",
      " [0.5849729 ]\n",
      " [0.5830493 ]\n",
      " [0.5820605 ]\n",
      " [0.5797653 ]\n",
      " [0.58706564]\n",
      " [0.5989736 ]\n",
      " [0.6107097 ]\n",
      " [0.6256107 ]\n",
      " [0.64625776]\n",
      " [0.64164656]\n",
      " [0.63904285]\n",
      " [0.63809717]\n",
      " [0.63965416]\n",
      " [0.6401421 ]]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot(p,color='red', label='prediction')\n",
    "plt2.plot(y_test,color='blue', label='y_test')\n",
    "plt2.legend(loc='upper left')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
